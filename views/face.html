<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Detection & Liveness (Blink Detection)</title>

    <script src="https://cdn.jsdelivr.net/npm/@vladmandic/face-api@1/dist/face-api.js"></script>

    <style>
        body {
            padding: 0;
            margin: 0;
            width: 100vw;
            height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            flex-direction: column;
            background-color: #383838;
            font-family: Arial, sans-serif;
        }

        #video-container {
            position: relative;
            width: 720px;
            height: 560px;
            display: flex;
            justify-content: center;
            align-items: center;
        }

        video {
            position: absolute;
            /* width: 100%;
            height: 100%; */
            border-radius: 16px;
            object-fit: cover;
        }

        canvas {
            position: absolute;
        }

        #instruction {
            position: absolute;
            top: -10%;
            font-size: 24px;
            color: white;
            font-weight: bold;
            text-align: center;
        }

        #warning {
            margin-top: 20px;
            color: red;
            font-size: 18px;
            font-weight: bold;
        }
    </style>
</head>

<body>
    <video id="video" width="720" height="560" autoplay muted></video>


    <script defer>
        const video = document.getElementById('video')

        Promise.all([
            faceapi.nets.tinyFaceDetector.loadFromUri('/models'),
            faceapi.nets.faceLandmark68Net.loadFromUri('/models'),
            faceapi.nets.faceRecognitionNet.loadFromUri('/models'),
            faceapi.nets.faceExpressionNet.loadFromUri('/models')
        ]).then(startVideo)

        function startVideo() {
            navigator.getUserMedia(
                { video: {} },
                stream => video.srcObject = stream,
                err => console.error(err)
            )
        }

        video.addEventListener('play', () => {
            const canvas = faceapi.createCanvasFromMedia(video)
            document.body.append(canvas)
            const displaySize = { width: video.width, height: video.height }
            faceapi.matchDimensions(canvas, displaySize)
            setInterval(async () => {
                const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceExpressions()
                const resizedDetections = faceapi.resizeResults(detections, displaySize)
                canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height)
                faceapi.draw.drawDetections(canvas, resizedDetections)
                faceapi.draw.drawFaceLandmarks(canvas, resizedDetections)
                faceapi.draw.drawFaceExpressions(canvas, resizedDetections)
            }, 100)
        })
    </script>
</body>

</html>